{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Molecular Representation using Graph Neural Network - Training Molecular Graph\n",
    "\n",
    "> Taking a look at how graph neural network operate for molecular representations\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [rdkit, machine learning, graph neural network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "In the [previous post](https://sunhwan.github.io/blog/2021/02/20/Learning-Molecular-Representation-Using-Graph-Neural-Network-Molecular-Graph.html), I have looked into how a molecular graph is constructed and message can be passed around in a MPNN architecture. In this post, I'll take a look at how the graph neural net can be trained. The details of message passing update will vary by implementation; here we choose what was used in this [paper](http://dx.doi.org/10.1021/acs.jcim.9b00237).\n",
    "\n",
    "Again, many code examples were taken from [chemprop](https://github.com/chemprop/chemprop) repository. The code was initially taken from the chemprop repository and I edited them for the sake of simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "![feature](files/molecular_graph_features.png)\n",
    "\n",
    "Let's briefly recap how the molecular graph is constructed and messages are passed around. As shown in the above figure, each atom and bonds are labeled as $x$ and $e$. Here we are discussing D-MPNN, which represents the graph with a directional edges, which means, for each bond between two atoms $v$ and $w$, there are two directional bond, $e_{vw}$ and $e_{wv}$. \n",
    "\n",
    "The initial hidden message is constructed as $h_{vw}^0 = \\tau (W_i \\mathrm{cat}(x_v, e_{vw}))$ where $W_i$ is a learned matrix and $\\tau$ is an activation function. \n",
    "\n",
    "![message](files/molecular_graph_message.png)\n",
    "\n",
    "Above figure shows two messages, $m_{57}$ and $m_{54}$, are constructed. First, the message from atom $v$ to $w$ is the sum of all the hidden state for the incoming bonds to $v$ (excluding the one originating from $w$). Then the learned matrix $W_m$ is multiplied to the message and the initial hidden message is added to form the new hidden message for the depth 1. This is repeated several times for the message to be passed around to multiple depth. \n",
    "\n",
    "After the messages are passed up to the given number of depth, the hidden states are summed to be a final message per each atom (all incoming hidden state) and the hidden state for each atom is computed as follows:\n",
    "\n",
    "\n",
    "$$m_v = \\sum_{k \\in N(v)} h_{kv}^t$$\n",
    "\n",
    "$$h_v = \\tau(W_a \\mathrm{cat} (x_v, m_v))$$\n",
    "\n",
    "Finally, the readout phase uses the sum of all $h_v$ to obtain the feature vector of the molecule and property prediction is carried out using a fully-connected feed forward network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data\n",
    "\n",
    "As an example, I'll use Enamine Real's diversity discovery set composed of 10240 compounds. This dataset contains some molecular properties, such as ClogP and TPSA, so we should be able to train a GCNN that predicts those properties.\n",
    "\n",
    "For this example, let's train using ClogP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.03.2\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "\n",
    "# RDKit \n",
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import rdRGroupDecomposition\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "\n",
    "DrawingOptions.bondLineWidth=1.8\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.warning')\n",
    "print(rdkit.__version__)\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch import nn\n",
    "\n",
    "# misc\n",
    "from typing import Dict, Iterator, List, Optional, Union, OrderedDict, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "# we will define a class which holds various parameter for D-MPNN\n",
    "class TrainArgs:\n",
    "    smiles_column = None\n",
    "    no_cuda = False\n",
    "    gpu = None\n",
    "    num_workers = 8\n",
    "    batch_size = 50\n",
    "    no_cache_mol = False\n",
    "    dataset_type = 'regression'\n",
    "    task_names = []\n",
    "    seed = 0\n",
    "    hidden_size = 300\n",
    "    bias = False\n",
    "    depth = 3\n",
    "    dropout = 0.0\n",
    "    undirected = False\n",
    "    aggregation = 'mean'\n",
    "    aggregation_norm = 100\n",
    "    ffn_num_layers = 2\n",
    "    ffn_hidden_size = 300\n",
    "    init_lr = 1e-4\n",
    "    max_lr = 1e-3\n",
    "    final_lr = 1e-4\n",
    "    num_lrs = 1\n",
    "    warmup_epochs = 2.0\n",
    "    epochs = 30\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        \"\"\"The :code:`torch.device` on which to load and process data and models.\"\"\"\n",
    "        if not self.cuda:\n",
    "            return torch.device('cpu')\n",
    "\n",
    "        return torch.device('cuda', self.gpu)\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, device: torch.device) -> None:\n",
    "        self.cuda = device.type == 'cuda'\n",
    "        self.gpu = device.index\n",
    "\n",
    "    @property\n",
    "    def cuda(self) -> bool:\n",
    "        \"\"\"Whether to use CUDA (i.e., GPUs) or not.\"\"\"\n",
    "        return not self.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    @cuda.setter\n",
    "    def cuda(self, cuda: bool) -> None:\n",
    "        self.no_cuda = not cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs()\n",
    "args.data_path = 'files/enamine_discovery_diversity_set_10240.csv'\n",
    "args.target_column = 'ClogP'\n",
    "args.smiles_column = 'SMILES'\n",
    "args.dataset_type = 'regression'\n",
    "args.task_names = [args.target_column]\n",
    "args.num_tasks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Catalog ID</th>\n",
       "      <th>PlateID</th>\n",
       "      <th>Well</th>\n",
       "      <th>MW (desalted)</th>\n",
       "      <th>ClogP</th>\n",
       "      <th>HBD</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>RotBonds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CN(C(=O)NC1CCOc2ccccc21)C(c1ccccc1)c1ccccn1</td>\n",
       "      <td>Z447596076</td>\n",
       "      <td>1186474-R-001</td>\n",
       "      <td>A02</td>\n",
       "      <td>373.448</td>\n",
       "      <td>2.419</td>\n",
       "      <td>1</td>\n",
       "      <td>54.46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cn1cc(C(=O)N2CCC(OC3CCOC3)CC2)c(C2CC2)n1</td>\n",
       "      <td>Z2180753156</td>\n",
       "      <td>1186474-R-001</td>\n",
       "      <td>A03</td>\n",
       "      <td>319.399</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0</td>\n",
       "      <td>56.59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CC(=O)N(C)C1CCN(C(=O)c2ccccc2-c2ccccc2C(=O)O)CC1</td>\n",
       "      <td>Z2295858832</td>\n",
       "      <td>1186474-R-001</td>\n",
       "      <td>A04</td>\n",
       "      <td>380.437</td>\n",
       "      <td>0.559</td>\n",
       "      <td>1</td>\n",
       "      <td>77.92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>COCC1(CNc2cnccc2C#N)CCNCC1</td>\n",
       "      <td>Z2030994006</td>\n",
       "      <td>1186474-R-001</td>\n",
       "      <td>A05</td>\n",
       "      <td>260.335</td>\n",
       "      <td>0.902</td>\n",
       "      <td>2</td>\n",
       "      <td>69.97</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CCCCOc1ccc(-c2nnc3n2CCCC3)cc1OC</td>\n",
       "      <td>Z273627850</td>\n",
       "      <td>1186474-R-001</td>\n",
       "      <td>A06</td>\n",
       "      <td>301.383</td>\n",
       "      <td>3.227</td>\n",
       "      <td>0</td>\n",
       "      <td>49.17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name                                            SMILES   Catalog ID  \\\n",
       "0   NaN       CN(C(=O)NC1CCOc2ccccc21)C(c1ccccc1)c1ccccn1   Z447596076   \n",
       "1   NaN          Cn1cc(C(=O)N2CCC(OC3CCOC3)CC2)c(C2CC2)n1  Z2180753156   \n",
       "2   NaN  CC(=O)N(C)C1CCN(C(=O)c2ccccc2-c2ccccc2C(=O)O)CC1  Z2295858832   \n",
       "3   NaN                        COCC1(CNc2cnccc2C#N)CCNCC1  Z2030994006   \n",
       "4   NaN                   CCCCOc1ccc(-c2nnc3n2CCCC3)cc1OC   Z273627850   \n",
       "\n",
       "         PlateID Well  MW (desalted)  ClogP  HBD   TPSA  RotBonds  \n",
       "0  1186474-R-001  A02        373.448  2.419    1  54.46         4  \n",
       "1  1186474-R-001  A03        319.399 -0.570    0  56.59         4  \n",
       "2  1186474-R-001  A04        380.437  0.559    1  77.92         4  \n",
       "3  1186474-R-001  A05        260.335  0.902    2  69.97         5  \n",
       "4  1186474-R-001  A06        301.383  3.227    0  49.17         6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(args.data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "from random import Random\n",
    "\n",
    "# Cache of graph featurizations\n",
    "CACHE_GRAPH = True\n",
    "SMILES_TO_GRAPH = {}\n",
    "\n",
    "def cache_graph():\n",
    "    return CACHE_GRAPH\n",
    "\n",
    "def set_cache_graph(cache_graph):\n",
    "    global CACHE_GRAPH\n",
    "    CACHE_GRAPH = cache_graph\n",
    "\n",
    "# Cache of RDKit molecules\n",
    "CACHE_MOL = True\n",
    "SMILES_TO_MOL: Dict[str, Chem.Mol] = {}\n",
    "\n",
    "def cache_mol() -> bool:\n",
    "    r\"\"\"Returns whether RDKit molecules will be cached.\"\"\"\n",
    "    return CACHE_MOL\n",
    "\n",
    "def set_cache_mol(cache_mol: bool) -> None:\n",
    "    r\"\"\"Sets whether RDKit molecules will be cached.\"\"\"\n",
    "    global CACHE_MOL\n",
    "    CACHE_MOL = cache_mol\n",
    "    \n",
    "# Atom feature sizes\n",
    "MAX_ATOMIC_NUM = 100\n",
    "ATOM_FEATURES = {\n",
    "    'atomic_num': list(range(MAX_ATOMIC_NUM)),\n",
    "    'degree': [0, 1, 2, 3, 4, 5],\n",
    "    'formal_charge': [-1, -2, 1, 2, 0],\n",
    "    'chiral_tag': [0, 1, 2, 3],\n",
    "    'num_Hs': [0, 1, 2, 3, 4],\n",
    "    'hybridization': [\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Distance feature sizes\n",
    "PATH_DISTANCE_BINS = list(range(10))\n",
    "THREE_D_DISTANCE_MAX = 20\n",
    "THREE_D_DISTANCE_STEP = 1\n",
    "THREE_D_DISTANCE_BINS = list(range(0, THREE_D_DISTANCE_MAX + 1, THREE_D_DISTANCE_STEP))\n",
    "\n",
    "# len(choices) + 1 to include room for uncommon values; + 2 at end for IsAromatic and mass\n",
    "ATOM_FDIM = sum(len(choices) + 1 for choices in ATOM_FEATURES.values()) + 2\n",
    "EXTRA_ATOM_FDIM = 0\n",
    "BOND_FDIM = 14\n",
    "\n",
    "\n",
    "def get_atom_fdim():\n",
    "    \"\"\"Gets the dimensionality of the atom feature vector.\"\"\"\n",
    "    return ATOM_FDIM + EXTRA_ATOM_FDIM\n",
    "\n",
    "def get_bond_fdim(atom_messages=False):\n",
    "    \"\"\"Gets the dimensionality of the bond feature vector.\n",
    "    \"\"\"\n",
    "    return BOND_FDIM + (not atom_messages) * get_atom_fdim()\n",
    "\n",
    "def onek_encoding_unk(value: int, choices: List[int]):\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding\n",
    "\n",
    "def atom_features(atom: Chem.rdchem.Atom, functional_groups: List[int] = None):\n",
    "    \"\"\"Builds a feature vector for an atom.\n",
    "    \"\"\"\n",
    "    features = onek_encoding_unk(atom.GetAtomicNum() - 1, ATOM_FEATURES['atomic_num']) + \\\n",
    "               onek_encoding_unk(atom.GetTotalDegree(), ATOM_FEATURES['degree']) + \\\n",
    "               onek_encoding_unk(atom.GetFormalCharge(), ATOM_FEATURES['formal_charge']) + \\\n",
    "               onek_encoding_unk(int(atom.GetChiralTag()), ATOM_FEATURES['chiral_tag']) + \\\n",
    "               onek_encoding_unk(int(atom.GetTotalNumHs()), ATOM_FEATURES['num_Hs']) + \\\n",
    "               onek_encoding_unk(int(atom.GetHybridization()), ATOM_FEATURES['hybridization']) + \\\n",
    "               [1 if atom.GetIsAromatic() else 0] + \\\n",
    "               [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "    if functional_groups is not None:\n",
    "        features += functional_groups\n",
    "    return features\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond):\n",
    "    \"\"\"Builds a feature vector for a bond.\n",
    "    \"\"\"\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (BOND_FDIM - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            (bond.GetIsConjugated() if bt is not None else 0),\n",
    "            (bond.IsInRing() if bt is not None else 0)\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond\n",
    "    \n",
    "class MoleculeDatapoint:\n",
    "    def __init__(self,\n",
    "                 smiles: str,\n",
    "                 targets: List[Optional[float]] = None,\n",
    "                 row: OrderedDict = None):\n",
    "        \n",
    "        self.smiles = smiles\n",
    "        self.targets = targets\n",
    "        self.features = []\n",
    "        self.row = row\n",
    "\n",
    "    @property\n",
    "    def mol(self) -> Chem.Mol:\n",
    "        \"\"\"Gets the corresponding list of RDKit molecules for the corresponding SMILES.\"\"\"\n",
    "        mol = SMILES_TO_MOL.get(self.smiles, Chem.MolFromSmiles(self.smiles))\n",
    "        if cache_mol():\n",
    "            SMILES_TO_MOL[self.smiles] = mol\n",
    "        return mol\n",
    "\n",
    "    def set_features(self, features: np.ndarray) -> None:\n",
    "        \"\"\"Sets the features of the molecule.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "\n",
    "    def extend_features(self, features: np.ndarray) -> None:\n",
    "        \"\"\"Extends the features of the molecule.\n",
    "        \"\"\"\n",
    "        self.features = np.append(self.features, features) if self.features is not None else features\n",
    "\n",
    "    def num_tasks(self) -> int:\n",
    "        \"\"\"Returns the number of prediction tasks.\n",
    "        \"\"\"\n",
    "        return len(self.targets)\n",
    "\n",
    "    def set_targets(self, targets: List[Optional[float]]):\n",
    "        \"\"\"Sets the targets of a molecule.\n",
    "        \"\"\"\n",
    "        self.targets = targets\n",
    "\n",
    "    def reset_features_and_targets(self) -> None:\n",
    "        \"\"\"Resets the features and targets to their raw values.\"\"\"\n",
    "        self.features, self.targets = self.raw_features, self.raw_targets\n",
    "        \n",
    "        \n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, data: List[MoleculeDatapoint]):\n",
    "        self._data = data\n",
    "        self._scaler = None\n",
    "        self._batch_graph = None\n",
    "        self._random = Random()\n",
    "\n",
    "    def smiles(self) -> List[str]:\n",
    "        return [d.smiles for d in self._data]\n",
    "\n",
    "    def mols(self) -> List[Chem.Mol]:\n",
    "        return [d.mol for d in self._data]\n",
    "\n",
    "    def targets(self) -> List[List[Optional[float]]]:\n",
    "        return [d.targets for d in self._data]\n",
    "\n",
    "    def num_tasks(self) -> int:\n",
    "        return self._data[0].num_tasks() if len(self._data) > 0 else None\n",
    "\n",
    "    def set_targets(self, targets: List[List[Optional[float]]]) -> None:\n",
    "        assert len(self._data) == len(targets)\n",
    "        for i in range(len(self._data)):\n",
    "            self._data[i].set_targets(targets[i])\n",
    "\n",
    "    def reset_features_and_targets(self) -> None:\n",
    "        for d in self._data:\n",
    "            d.reset_features_and_targets()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, item) -> Union[MoleculeDatapoint, List[MoleculeDatapoint]]:\n",
    "        return self._data[item]\n",
    "    \n",
    "    def batch_graph(self):\n",
    "        if self._batch_graph is None:\n",
    "            self._batch_graph = []\n",
    "\n",
    "            mol_graphs = []\n",
    "            for d in self._data:\n",
    "                mol_graphs_list = []\n",
    "                if d.smiles in SMILES_TO_GRAPH:\n",
    "                    mol_graph = SMILES_TO_GRAPH[d.smiles]\n",
    "                else:\n",
    "                    mol_graph = MolGraph(d.mol)\n",
    "                    if cache_graph():\n",
    "                        SMILES_TO_GRAPH[d.smiles] = mol_graph\n",
    "                mol_graphs.append([mol_graph])\n",
    "\n",
    "            self._batch_graph = [BatchMolGraph([g[i] for g in mol_graphs]) for i in range(len(mol_graphs[0]))]\n",
    "\n",
    "        return self._batch_graph\n",
    "    \n",
    "    def features(self) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Returns the features associated with each molecule (if they exist).\n",
    "\n",
    "        :return: A list of 1D numpy arrays containing the features for each molecule or None if there are no features.\n",
    "        \"\"\"\n",
    "        if len(self._data) == 0 or self._data[0].features is None:\n",
    "            return None\n",
    "\n",
    "        return [d.features for d in self._data]\n",
    "    \n",
    "\n",
    "def index_select_ND(source: torch.Tensor, index: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Selects the message features from source corresponding to the atom or bond indices in index.\n",
    "    \"\"\"\n",
    "    index_size = index.size()             # (num_atoms/num_bonds, max_num_bonds)\n",
    "    suffix_dim = source.size()[1:]        # (hidden_size,)\n",
    "    final_size = index_size + suffix_dim  # (num_atoms/num_bonds, max_num_bonds, hidden_size)\n",
    "\n",
    "    target = source.index_select(dim=0, index=index.view(-1)) # (num_atoms/num_bonds * max_num_bonds, hidden_size)\n",
    "    target = target.view(final_size)                          # (num_atoms/num_bonds, max_num_bonds, hidden_size)\n",
    "    return target\n",
    "\n",
    "class MolGraph:\n",
    "    def __init__(self, mol, atom_descriptors=None):\n",
    "        # Convert SMILES to RDKit molecule if necessary\n",
    "        if type(mol) == str:\n",
    "            mol = Chem.MolFromSmiles(mol)\n",
    "\n",
    "        self.n_atoms = 0  # number of atoms\n",
    "        self.n_bonds = 0  # number of bonds\n",
    "        self.f_atoms = []  # mapping from atom index to atom features\n",
    "        self.f_bonds = []  # mapping from bond index to concat(in_atom, bond) features\n",
    "        self.a2b = []  # mapping from atom index to incoming bond indices\n",
    "        self.b2a = []  # mapping from bond index to the index of the atom the bond is coming from\n",
    "        self.b2revb = []  # mapping from bond index to the index of the reverse bond\n",
    "\n",
    "        # Get atom features\n",
    "        self.f_atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "        if atom_descriptors is not None:\n",
    "            self.f_atoms = [f_atoms + descs.tolist() for f_atoms, descs in zip(self.f_atoms, atom_descriptors)]\n",
    "\n",
    "        self.n_atoms = len(self.f_atoms)\n",
    "\n",
    "        # Initialize atom to bond mapping for each atom\n",
    "        for _ in range(self.n_atoms):\n",
    "            self.a2b.append([])\n",
    "\n",
    "        # Get bond features\n",
    "        for a1 in range(self.n_atoms):\n",
    "            for a2 in range(a1 + 1, self.n_atoms):\n",
    "                bond = mol.GetBondBetweenAtoms(a1, a2)\n",
    "\n",
    "                if bond is None:\n",
    "                    continue\n",
    "\n",
    "                f_bond = bond_features(bond)\n",
    "                self.f_bonds.append(self.f_atoms[a1] + f_bond)\n",
    "                self.f_bonds.append(self.f_atoms[a2] + f_bond)\n",
    "\n",
    "                # Update index mappings\n",
    "                b1 = self.n_bonds\n",
    "                b2 = b1 + 1\n",
    "                self.a2b[a2].append(b1)  # b1 = a1 --> a2\n",
    "                self.b2a.append(a1)\n",
    "                self.a2b[a1].append(b2)  # b2 = a2 --> a1\n",
    "                self.b2a.append(a2)\n",
    "                self.b2revb.append(b2)\n",
    "                self.b2revb.append(b1)\n",
    "                self.n_bonds += 2\n",
    "\n",
    "\n",
    "class BatchMolGraph:\n",
    "    \"\"\"A `BatchMolGraph` represents the graph structure and featurization of a batch of molecules.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mol_graphs: List[MolGraph]):\n",
    "        self.atom_fdim = get_atom_fdim()\n",
    "        self.bond_fdim = get_bond_fdim()\n",
    "\n",
    "        # Start n_atoms and n_bonds at 1 b/c zero padding\n",
    "        self.n_atoms = 1  # number of atoms (start at 1 b/c need index 0 as padding)\n",
    "        self.n_bonds = 1  # number of bonds (start at 1 b/c need index 0 as padding)\n",
    "        self.a_scope = []  # list of tuples indicating (start_atom_index, num_atoms) for each molecule\n",
    "        self.b_scope = []  # list of tuples indicating (start_bond_index, num_bonds) for each molecule\n",
    "\n",
    "        # All start with zero padding so that indexing with zero padding returns zeros\n",
    "        f_atoms = [[0] * self.atom_fdim]  # atom features\n",
    "        f_bonds = [[0] * self.bond_fdim]  # combined atom/bond features\n",
    "        a2b = [[]]  # mapping from atom index to incoming bond indices\n",
    "        b2a = [0]  # mapping from bond index to the index of the atom the bond is coming from\n",
    "        b2revb = [0]  # mapping from bond index to the index of the reverse bond\n",
    "        for mol_graph in mol_graphs:\n",
    "            f_atoms.extend(mol_graph.f_atoms)\n",
    "            f_bonds.extend(mol_graph.f_bonds)\n",
    "\n",
    "            for a in range(mol_graph.n_atoms):\n",
    "                a2b.append([b + self.n_bonds for b in mol_graph.a2b[a]])\n",
    "\n",
    "            for b in range(mol_graph.n_bonds):\n",
    "                b2a.append(self.n_atoms + mol_graph.b2a[b])\n",
    "                b2revb.append(self.n_bonds + mol_graph.b2revb[b])\n",
    "\n",
    "            self.a_scope.append((self.n_atoms, mol_graph.n_atoms))\n",
    "            self.b_scope.append((self.n_bonds, mol_graph.n_bonds))\n",
    "            self.n_atoms += mol_graph.n_atoms\n",
    "            self.n_bonds += mol_graph.n_bonds\n",
    "\n",
    "        self.max_num_bonds = max(1, max(len(in_bonds) for in_bonds in a2b))  # max with 1 to fix a crash in rare case of all single-heavy-atom mols\n",
    "\n",
    "        self.f_atoms = torch.FloatTensor(f_atoms)\n",
    "        self.f_bonds = torch.FloatTensor(f_bonds)\n",
    "        self.a2b = torch.LongTensor([a2b[a] + [0] * (self.max_num_bonds - len(a2b[a])) for a in range(self.n_atoms)])\n",
    "        self.b2a = torch.LongTensor(b2a)\n",
    "        self.b2revb = torch.LongTensor(b2revb)\n",
    "        self.b2b = None  # try to avoid computing b2b b/c O(n_atoms^3)\n",
    "        self.a2a = None  # only needed if using atom messages\n",
    "\n",
    "    def get_components(self, atom_messages: bool = False) -> Tuple[torch.FloatTensor, torch.FloatTensor,\n",
    "                                                                   torch.LongTensor, torch.LongTensor, torch.LongTensor,\n",
    "                                                                   List[Tuple[int, int]], List[Tuple[int, int]]]:\n",
    "        return self.f_atoms, self.f_bonds, self.a2b, self.b2a, self.b2revb, self.a_scope, self.b_scope\n",
    "\n",
    "    def get_b2b(self) -> torch.LongTensor:\n",
    "        \"\"\"Computes (if necessary) and returns a mapping from each bond index to all the incoming bond indices.\n",
    "        \"\"\"\n",
    "        if self.b2b is None:\n",
    "            b2b = self.a2b[self.b2a]  # num_bonds x max_num_bonds\n",
    "            # b2b includes reverse edge for each bond so need to mask out\n",
    "            revmask = (b2b != self.b2revb.unsqueeze(1).repeat(1, b2b.size(1))).long()  # num_bonds x max_num_bonds\n",
    "            self.b2b = b2b * revmask\n",
    "\n",
    "        return self.b2b\n",
    "\n",
    "    def get_a2a(self) -> torch.LongTensor:\n",
    "        \"\"\"Computes (if necessary) and returns a mapping from each atom index to all neighboring atom indices.\n",
    "        \"\"\"\n",
    "        if self.a2a is None:\n",
    "            # b = a1 --> a2\n",
    "            # a2b maps a2 to all incoming bonds b\n",
    "            # b2a maps each bond b to the atom it comes from a1\n",
    "            # thus b2a[a2b] maps atom a2 to neighboring atoms a1\n",
    "            self.a2a = self.b2a[self.a2b]  # num_atoms x max_num_bonds\n",
    "\n",
    "        return self.a2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MoleculeDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-018356360359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prepare data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m data = MoleculeDataset([\n\u001b[0m\u001b[1;32m      3\u001b[0m     MoleculeDatapoint(\n\u001b[1;32m      4\u001b[0m         \u001b[0msmiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MoleculeDataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare data set\n",
    "data = MoleculeDataset([\n",
    "    MoleculeDatapoint(\n",
    "        smiles=row[args.smiles_column],\n",
    "        targets=[row[args.target_column]]\n",
    "    ) for i, row in df.iterrows()\n",
    "])\n",
    "\n",
    "# split data into train, validation and test set\n",
    "random = Random()\n",
    "sizes = [0.8, 0.1, 0.1]\n",
    "\n",
    "indices = list(range(len(data)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(sizes[0] * len(data))\n",
    "train_val_size = int((sizes[0] + sizes[1]) * len(data))\n",
    "\n",
    "train = [data[i] for i in indices[:train_size]]\n",
    "val = [data[i] for i in indices[train_size:train_val_size]]\n",
    "test = [data[i] for i in indices[train_val_size:]]\n",
    "\n",
    "train_data = MoleculeDataset(train)\n",
    "val_data = MoleculeDataset(val)\n",
    "test_data = MoleculeDataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPNN Model\n",
    "\n",
    "Let's create a MPNN model. The model is composed of encoder and feed-forward network (FFN). The encoder is same as the one we discussed before and the FFN is defined as a straightforward neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "# Atom feature sizes\n",
    "MAX_ATOMIC_NUM = 100\n",
    "ATOM_FEATURES = {\n",
    "    'atomic_num': list(range(MAX_ATOMIC_NUM)),\n",
    "    'degree': [0, 1, 2, 3, 4, 5],\n",
    "    'formal_charge': [-1, -2, 1, 2, 0],\n",
    "    'chiral_tag': [0, 1, 2, 3],\n",
    "    'num_Hs': [0, 1, 2, 3, 4],\n",
    "    'hybridization': [\n",
    "        Chem.rdchem.HybridizationType.SP,\n",
    "        Chem.rdchem.HybridizationType.SP2,\n",
    "        Chem.rdchem.HybridizationType.SP3,\n",
    "        Chem.rdchem.HybridizationType.SP3D,\n",
    "        Chem.rdchem.HybridizationType.SP3D2\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Distance feature sizes\n",
    "PATH_DISTANCE_BINS = list(range(10))\n",
    "THREE_D_DISTANCE_MAX = 20\n",
    "THREE_D_DISTANCE_STEP = 1\n",
    "THREE_D_DISTANCE_BINS = list(range(0, THREE_D_DISTANCE_MAX + 1, THREE_D_DISTANCE_STEP))\n",
    "\n",
    "# len(choices) + 1 to include room for uncommon values; + 2 at end for IsAromatic and mass\n",
    "ATOM_FDIM = sum(len(choices) + 1 for choices in ATOM_FEATURES.values()) + 2\n",
    "EXTRA_ATOM_FDIM = 0\n",
    "BOND_FDIM = 14\n",
    "\n",
    "\n",
    "def get_atom_fdim() -> int:\n",
    "    \"\"\"Gets the dimensionality of the atom feature vector.\"\"\"\n",
    "    return ATOM_FDIM + EXTRA_ATOM_FDIM\n",
    "\n",
    "def get_bond_fdim() -> int:\n",
    "    \"\"\"Gets the dimensionality of the bond feature vector.\n",
    "    \"\"\"\n",
    "    return BOND_FDIM + get_atom_fdim()\n",
    "\n",
    "\n",
    "def onek_encoding_unk(value: int, choices: List[int]) -> List[int]:\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding\n",
    "\n",
    "def atom_features(atom: Chem.rdchem.Atom, functional_groups: List[int] = None) -> List[Union[bool, int, float]]:\n",
    "    \"\"\"Builds a feature vector for an atom.\n",
    "    \"\"\"\n",
    "    features = onek_encoding_unk(atom.GetAtomicNum() - 1, ATOM_FEATURES['atomic_num']) + \\\n",
    "               onek_encoding_unk(atom.GetTotalDegree(), ATOM_FEATURES['degree']) + \\\n",
    "               onek_encoding_unk(atom.GetFormalCharge(), ATOM_FEATURES['formal_charge']) + \\\n",
    "               onek_encoding_unk(int(atom.GetChiralTag()), ATOM_FEATURES['chiral_tag']) + \\\n",
    "               onek_encoding_unk(int(atom.GetTotalNumHs()), ATOM_FEATURES['num_Hs']) + \\\n",
    "               onek_encoding_unk(int(atom.GetHybridization()), ATOM_FEATURES['hybridization']) + \\\n",
    "               [1 if atom.GetIsAromatic() else 0] + \\\n",
    "               [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "    if functional_groups is not None:\n",
    "        features += functional_groups\n",
    "    return features\n",
    "\n",
    "\n",
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"Initializes the weights of a model in place.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant_(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal_(param)\n",
    "\n",
    "class MPNEncoder(nn.Module):\n",
    "    def __init__(self, args, atom_fdim, bond_fdim):\n",
    "        super(MPNEncoder, self).__init__()\n",
    "        self.atom_fdim = atom_fdim\n",
    "        self.bond_fdim = bond_fdim\n",
    "        self.hidden_size = args.hidden_size\n",
    "        self.bias = args.bias\n",
    "        self.depth = args.depth\n",
    "        self.dropout = args.dropout\n",
    "        self.layers_per_message = 1\n",
    "        self.undirected = False\n",
    "        self.atom_messages = False\n",
    "        self.device = args.device\n",
    "        self.aggregation = args.aggregation\n",
    "        self.aggregation_norm = args.aggregation_norm\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "        self.act_func = nn.ReLU()\n",
    "        self.cached_zero_vector = nn.Parameter(torch.zeros(self.hidden_size), requires_grad=False)\n",
    "\n",
    "        # Input\n",
    "        input_dim = self.bond_fdim\n",
    "        self.W_i = nn.Linear(input_dim, self.hidden_size, bias=self.bias)\n",
    "        w_h_input_size = self.hidden_size\n",
    "\n",
    "        # Shared weight matrix across depths (default)\n",
    "        self.W_h = nn.Linear(w_h_input_size, self.hidden_size, bias=self.bias)\n",
    "        self.W_o = nn.Linear(self.atom_fdim + self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, mol_graph):\n",
    "        \"\"\"Encodes a batch of molecular graphs.\n",
    "        \"\"\"\n",
    "        f_atoms, f_bonds, a2b, b2a, b2revb, a_scope, b_scope = mol_graph.get_components()\n",
    "        f_atoms, f_bonds, a2b, b2a, b2revb = f_atoms.to(self.device), f_bonds.to(self.device), a2b.to(self.device), b2a.to(self.device), b2revb.to(self.device)\n",
    "\n",
    "        input = self.W_i(f_bonds)  # num_bonds x hidden_size\n",
    "        message = self.act_func(input)  # num_bonds x hidden_size\n",
    "\n",
    "        # Message passing\n",
    "        for depth in range(self.depth - 1):\n",
    "            # m(a1 -> a2) = [sum_{a0 \\in nei(a1)} m(a0 -> a1)] - m(a2 -> a1)\n",
    "            # message      a_message = sum(nei_a_message)      rev_message\n",
    "            nei_a_message = index_select_ND(message, a2b)  # num_atoms x max_num_bonds x hidden\n",
    "            a_message = nei_a_message.sum(dim=1)  # num_atoms x hidden\n",
    "            rev_message = message[b2revb]  # num_bonds x hidden\n",
    "            message = a_message[b2a] - rev_message  # num_bonds x hidden\n",
    "\n",
    "            message = self.W_h(message)\n",
    "            message = self.act_func(input + message)  # num_bonds x hidden_size\n",
    "            message = self.dropout_layer(message)  # num_bonds x hidden\n",
    "\n",
    "        a2x = a2b\n",
    "        nei_a_message = index_select_ND(message, a2x)  # num_atoms x max_num_bonds x hidden\n",
    "        a_message = nei_a_message.sum(dim=1)  # num_atoms x hidden\n",
    "        a_input = torch.cat([f_atoms, a_message], dim=1)  # num_atoms x (atom_fdim + hidden)\n",
    "        atom_hiddens = self.act_func(self.W_o(a_input))  # num_atoms x hidden\n",
    "        atom_hiddens = self.dropout_layer(atom_hiddens)  # num_atoms x hidden\n",
    "\n",
    "        # Readout\n",
    "        mol_vecs = []\n",
    "        for i, (a_start, a_size) in enumerate(a_scope):\n",
    "            if a_size == 0:\n",
    "                mol_vecs.append(self.cached_zero_vector)\n",
    "            else:\n",
    "                cur_hiddens = atom_hiddens.narrow(0, a_start, a_size)\n",
    "                mol_vec = cur_hiddens  # (num_atoms, hidden_size)\n",
    "                if self.aggregation == 'mean':\n",
    "                    mol_vec = mol_vec.sum(dim=0) / a_size\n",
    "                elif self.aggregation == 'sum':\n",
    "                    mol_vec = mol_vec.sum(dim=0)\n",
    "                elif self.aggregation == 'norm':\n",
    "                    mol_vec = mol_vec.sum(dim=0) / self.aggregation_norm\n",
    "                mol_vecs.append(mol_vec)\n",
    "\n",
    "        mol_vecs = torch.stack(mol_vecs, dim=0)  # (num_molecules, hidden_size)\n",
    "\n",
    "        return mol_vecs  # num_molecules x hidden\n",
    "    \n",
    "\n",
    "class MPN(nn.Module):\n",
    "    def __init__(self, args, atom_fdim=None, bond_fdim=None):\n",
    "        super(MPN, self).__init__()\n",
    "        self.atom_fdim = atom_fdim or get_atom_fdim()\n",
    "        self.bond_fdim = bond_fdim or get_bond_fdim()\n",
    "        self.device = args.device\n",
    "        self.encoder = MPNEncoder(args, self.atom_fdim, self.bond_fdim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Encodes a batch of molecules.\n",
    "        \"\"\"\n",
    "        if type(batch[0]) != BatchMolGraph:\n",
    "            batch = [mol2graph(b) for b in batch]\n",
    "\n",
    "        encodings = [self.encoder(batch[0])]\n",
    "        output = reduce(lambda x, y: torch.cat((x, y), dim=1), encodings)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class MoleculeModel(nn.Module):\n",
    "    def __init__(self, args, featurizer=False):\n",
    "        super(MoleculeModel, self).__init__()\n",
    "\n",
    "        self.classification = args.dataset_type == 'classification'\n",
    "        self.featurizer = featurizer\n",
    "\n",
    "        self.output_size = args.num_tasks\n",
    "\n",
    "        if self.classification:\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "        self.create_encoder(args)\n",
    "        self.create_ffn(args)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def create_encoder(self, args):\n",
    "        self.encoder = MPN(args)\n",
    "\n",
    "    def create_ffn(self, args):\n",
    "        first_linear_dim = args.hidden_size\n",
    "        dropout = nn.Dropout(args.dropout)\n",
    "        activation = nn.ReLU()\n",
    "\n",
    "        # Create FFN layers\n",
    "        if args.ffn_num_layers == 1:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(first_linear_dim, self.output_size)\n",
    "            ]\n",
    "        else:\n",
    "            ffn = [\n",
    "                dropout,\n",
    "                nn.Linear(first_linear_dim, args.ffn_hidden_size)\n",
    "            ]\n",
    "            for _ in range(args.ffn_num_layers - 2):\n",
    "                ffn.extend([\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    nn.Linear(args.ffn_hidden_size, args.ffn_hidden_size),\n",
    "                ])\n",
    "            ffn.extend([\n",
    "                activation,\n",
    "                dropout,\n",
    "                nn.Linear(args.ffn_hidden_size, self.output_size),\n",
    "            ])\n",
    "\n",
    "        # Create FFN model\n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "\n",
    "    def featurize(self, batch, features_batch=None, atom_descriptors_batch=None):\n",
    "        \"\"\"Computes feature vectors of the input by running the model except for the last layer.\n",
    "        \"\"\"\n",
    "        return self.ffn[:-1](self.encoder(batch, features_batch, atom_descriptors_batch))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        output = self.ffn(self.encoder(batch))\n",
    "\n",
    "        # Don't apply sigmoid during training b/c using BCEWithLogitsLoss\n",
    "        if self.classification and not self.training:\n",
    "            output = self.sigmoid(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoleculeModel(args)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown below, the model is comprised of an encoder and FFN. The encoder has three learned matrices and the FFN has 2 fully-connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeModel(\n",
       "  (encoder): MPN(\n",
       "    (encoder): MPNEncoder(\n",
       "      (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "      (act_func): ReLU()\n",
       "      (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
       "      (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
       "      (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ffn): Sequential(\n",
       "    (0): Dropout(p=0.0, inplace=False)\n",
       "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import Adam, Optimizer\n",
    "\n",
    "class NoamLR(_LRScheduler):\n",
    "    \"\"\"\n",
    "    Noam learning rate scheduler with piecewise linear increase and exponential decay.\n",
    "\n",
    "    The learning rate increases linearly from init_lr to max_lr over the course of\n",
    "    the first warmup_steps (where :code:`warmup_steps = warmup_epochs * steps_per_epoch`).\n",
    "    Then the learning rate decreases exponentially from :code:`max_lr` to :code:`final_lr` over the\n",
    "    course of the remaining :code:`total_steps - warmup_steps` (where :code:`total_steps =\n",
    "    total_epochs * steps_per_epoch`). This is roughly based on the learning rate\n",
    "    schedule from `Attention is All You Need <https://arxiv.org/abs/1706.03762>`_, section 5.3.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 optimizer: Optimizer,\n",
    "                 warmup_epochs: List[Union[float, int]],\n",
    "                 total_epochs: List[int],\n",
    "                 steps_per_epoch: int,\n",
    "                 init_lr: List[float],\n",
    "                 max_lr: List[float],\n",
    "                 final_lr: List[float]):\n",
    "\n",
    "        assert len(optimizer.param_groups) == len(warmup_epochs) == len(total_epochs) == len(init_lr) == \\\n",
    "               len(max_lr) == len(final_lr)\n",
    "\n",
    "        self.num_lrs = len(optimizer.param_groups)\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = np.array(warmup_epochs)\n",
    "        self.total_epochs = np.array(total_epochs)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.init_lr = np.array(init_lr)\n",
    "        self.max_lr = np.array(max_lr)\n",
    "        self.final_lr = np.array(final_lr)\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.lr = init_lr\n",
    "        self.warmup_steps = (self.warmup_epochs * self.steps_per_epoch).astype(int)\n",
    "        self.total_steps = self.total_epochs * self.steps_per_epoch\n",
    "        self.linear_increment = (self.max_lr - self.init_lr) / self.warmup_steps\n",
    "\n",
    "        self.exponential_gamma = (self.final_lr / self.max_lr) ** (1 / (self.total_steps - self.warmup_steps))\n",
    "\n",
    "        super(NoamLR, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self) -> List[float]:\n",
    "        return list(self.lr)\n",
    "\n",
    "    def step(self, current_step: int = None):\n",
    "        if current_step is not None:\n",
    "            self.current_step = current_step\n",
    "        else:\n",
    "            self.current_step += 1\n",
    "\n",
    "        for i in range(self.num_lrs):\n",
    "            if self.current_step <= self.warmup_steps[i]:\n",
    "                self.lr[i] = self.init_lr[i] + self.current_step * self.linear_increment[i]\n",
    "            elif self.current_step <= self.total_steps[i]:\n",
    "                self.lr[i] = self.max_lr[i] * (self.exponential_gamma[i] ** (self.current_step - self.warmup_steps[i]))\n",
    "            else:  # theoretically this case should never be reached since training should stop at total_steps\n",
    "                self.lr[i] = self.final_lr[i]\n",
    "\n",
    "            self.optimizer.param_groups[i]['lr'] = self.lr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import threading\n",
    "\n",
    "def construct_molecule_batch(data):\n",
    "    data = MoleculeDataset(data)\n",
    "    data.batch_graph()  # Forces computation and caching of the BatchMolGraph for the molecules\n",
    "    return data\n",
    "\n",
    "class MoleculeSampler(Sampler):\n",
    "    def __init__(self, dataset, shuffle=False, seed=0):\n",
    "        super(Sampler, self).__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self._random = Random(seed)\n",
    "        self.positive_indices = self.negative_indices = None\n",
    "        self.length = len(self.dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        if self.shuffle:\n",
    "            self._random.shuffle(indices)\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "\n",
    "class MoleculeDataLoader(DataLoader):\n",
    "    def __init__(self,\n",
    "                 dataset: MoleculeDataset,\n",
    "                 batch_size: int = 50,\n",
    "                 num_workers: int = 8,\n",
    "                 shuffle: bool = False,\n",
    "                 seed: int = 0):\n",
    "\n",
    "        self._dataset = dataset\n",
    "        self._batch_size = batch_size\n",
    "        self._num_workers = num_workers\n",
    "        self._shuffle = shuffle\n",
    "        self._seed = seed\n",
    "        self._context = None\n",
    "        self._class_balance = False\n",
    "        self._timeout = 0\n",
    "        is_main_thread = threading.current_thread() is threading.main_thread()\n",
    "        \n",
    "        if not is_main_thread and self._num_workers > 0:\n",
    "            self._context = 'forkserver'  # In order to prevent a hanging\n",
    "            self._timeout = 3600  # Just for sure that the DataLoader won't hang\n",
    "\n",
    "        self._sampler = MoleculeSampler(\n",
    "            dataset=self._dataset,\n",
    "            shuffle=self._shuffle,\n",
    "            seed=self._seed\n",
    "        )\n",
    "\n",
    "        super(MoleculeDataLoader, self).__init__(\n",
    "            dataset=self._dataset,\n",
    "            batch_size=self._batch_size,\n",
    "            sampler=self._sampler,\n",
    "            num_workers=self._num_workers,\n",
    "            collate_fn=construct_molecule_batch,\n",
    "            multiprocessing_context=self._context,\n",
    "            timeout=self._timeout\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> List[List[Optional[float]]]:\n",
    "        if self._class_balance or self._shuffle:\n",
    "            raise ValueError('Cannot safely extract targets when class balance or shuffle are enabled.')\n",
    "\n",
    "        return [self._dataset[index].targets for index in self._sampler]\n",
    "\n",
    "    @property\n",
    "    def iter_size(self) -> int:\n",
    "        return len(self._sampler)\n",
    "\n",
    "    def __iter__(self) -> Iterator[MoleculeDataset]:\n",
    "        return super(MoleculeDataLoader, self).__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create data loaders\n",
    "train_data_loader = MoleculeDataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    seed=args.seed\n",
    ")\n",
    "val_data_loader = MoleculeDataLoader(\n",
    "    dataset=val_data,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=8\n",
    ")\n",
    "test_data_loader = MoleculeDataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimizer\n",
    "params = [{'params': model.parameters(), 'lr': args.init_lr, 'weight_decay': 0}]\n",
    "optimizer = Adam(params)\n",
    "\n",
    "# scheduler\n",
    "scheduler = NoamLR(\n",
    "    optimizer=optimizer,\n",
    "    warmup_epochs=[args.warmup_epochs],\n",
    "    total_epochs=[args.epochs] * args.num_lrs,\n",
    "    steps_per_epoch=len(train_data) // args.batch_size,\n",
    "    init_lr=[args.init_lr],\n",
    "    max_lr=[args.max_lr],\n",
    "    final_lr=[args.final_lr]\n",
    ")\n",
    "\n",
    "# loss function\n",
    "loss_func = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# train loop\n",
    "model.train()\n",
    "loss_sum = iter_count = 0\n",
    "n_iter = 0\n",
    "\n",
    "for batch in tqdm(train_data_loader, total=len(train_data_loader), leave=False):\n",
    "    mol_batch, target_batch = batch.batch_graph(), batch.targets()\n",
    "    mask = torch.Tensor([[x is not None for x in tb] for tb in target_batch])\n",
    "    targets = torch.Tensor([[0 if x is None else x for x in tb] for tb in target_batch])\n",
    "\n",
    "    # Run model\n",
    "    model.zero_grad()\n",
    "    preds = model(mol_batch)\n",
    "\n",
    "    # Move tensors to correct device\n",
    "    mask = mask.to(preds.device)\n",
    "    targets = targets.to(preds.device)\n",
    "    class_weights = torch.ones(targets.shape, device=preds.device)\n",
    "\n",
    "    loss = loss_func(preds, targets) * class_weights * mask\n",
    "    loss = loss.sum() / mask.sum()\n",
    "\n",
    "    loss_sum += loss.item()\n",
    "    iter_count += 1\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if isinstance(scheduler, NoamLR):\n",
    "        scheduler.step()\n",
    "\n",
    "    n_iter += len(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for the first epoch is finished. Let's take a look at how well the model predict the ClogP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "initial_preds = []\n",
    "\n",
    "for batch in tqdm(val_data_loader, disable=False, leave=False):\n",
    "    # Prepare batch\n",
    "    batch: MoleculeDataset\n",
    "    mol_batch = batch.batch_graph()\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        batch_preds = model(mol_batch)\n",
    "\n",
    "    batch_preds = batch_preds.data.cpu().numpy()\n",
    "\n",
    "    # Collect vectors\n",
    "    batch_preds = batch_preds.tolist()\n",
    "    initial_preds.extend(batch_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.0658553721115887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# valid_preds and valid_targets have shape (num_tasks, data_size)\n",
    "targets = val_data_loader.targets\n",
    "metric_func = mean_squared_error\n",
    "\n",
    "valid_preds = [[] for _ in range(args.num_tasks)]\n",
    "valid_targets = [[] for _ in range(args.num_tasks)]\n",
    "for i in range(args.num_tasks):\n",
    "    for j in range(len(preds)):\n",
    "        if targets[j][i] is not None:  # Skip those without targets\n",
    "            valid_preds[i].append(preds[j][i].detach())\n",
    "            valid_targets[i].append(targets[j][i])\n",
    "            \n",
    "result = metric_func(valid_targets[i], valid_preds[i])\n",
    "print('MSE:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = plt.figure(figsize=(4,4))\n",
    "plt.scatter(valid_targets[i], valid_preds[i])\n",
    "plt.xlabel('Target ClogP')\n",
    "plt.ylabel('Predicted ClogP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost no correlation as of first epoch. Let's train a few more epochs and see if the prediciton improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359ffb3caf3c4c6384cb067ac569d05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5059666700564436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6747574089163861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.29365952162247105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.2443422001168768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.22893787807471938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.24693692581926335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.18068380381421822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.16628313459548472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.15646424430563233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.14714968670153764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.1484021422019028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.1497949169195903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.1332405691696682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.12293908860736892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.12480342381848945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.12231600820223316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.12469534214189118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.12742151396520932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.10947115821963195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.11363330373825292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.10276127977714987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.10135583119599778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0.10164295643187546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.09673642613524305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.09645447176601984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0.0980465410170695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0.09245372955020192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0.08906743111716783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 0.0879800185507161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0.09138532813108272\n"
     ]
    }
   ],
   "source": [
    "scheduler = NoamLR(\n",
    "    optimizer=optimizer,\n",
    "    warmup_epochs=[args.warmup_epochs],\n",
    "    total_epochs=[args.epochs] * args.num_lrs,\n",
    "    steps_per_epoch=len(train_data) // args.batch_size,\n",
    "    init_lr=[args.init_lr],\n",
    "    max_lr=[args.max_lr],\n",
    "    final_lr=[args.final_lr]\n",
    ")\n",
    "\n",
    "loss_func = nn.MSELoss(reduction='none')\n",
    "\n",
    "optimizer = Adam(params)\n",
    "\n",
    "metric_func = mean_squared_error\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "\n",
    "    # train \n",
    "    model.train()\n",
    "\n",
    "    loss_sum = iter_count = 0\n",
    "    n_iter = 0\n",
    "\n",
    "    for batch in tqdm(train_data_loader, total=len(train_data_loader), leave=False):\n",
    "        mol_batch, target_batch = batch.batch_graph(), batch.targets()\n",
    "        mask = torch.Tensor([[x is not None for x in tb] for tb in target_batch])\n",
    "        targets = torch.Tensor([[0 if x is None else x for x in tb] for tb in target_batch])\n",
    "\n",
    "        # Run model\n",
    "        model.zero_grad()\n",
    "        preds = model(mol_batch)\n",
    "\n",
    "        # Move tensors to correct device\n",
    "        mask = mask.to(preds.device)\n",
    "        targets = targets.to(preds.device)\n",
    "        class_weights = torch.ones(targets.shape, device=preds.device)\n",
    "\n",
    "        loss = loss_func(preds, targets) * class_weights * mask\n",
    "        loss = loss.sum() / mask.sum()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        iter_count += 1\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if isinstance(scheduler, NoamLR):\n",
    "            scheduler.step()\n",
    "\n",
    "        n_iter += len(batch)\n",
    "\n",
    "    # eval\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for batch in tqdm(val_data_loader, disable=False, leave=False):\n",
    "        # Prepare batch\n",
    "        batch: MoleculeDataset\n",
    "        mol_batch = batch.batch_graph()\n",
    "\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            batch_preds = model(mol_batch)\n",
    "\n",
    "        batch_preds = batch_preds.data.cpu().numpy()\n",
    "\n",
    "        # Collect vectors\n",
    "        batch_preds = batch_preds.tolist()\n",
    "        preds.extend(batch_preds)\n",
    "\n",
    "    # valid_preds and valid_targets have shape (num_tasks, data_size)\n",
    "    num_tasks = 1\n",
    "    targets = val_data_loader.targets\n",
    "\n",
    "    valid_preds = [[] for _ in range(num_tasks)]\n",
    "    valid_targets = [[] for _ in range(num_tasks)]\n",
    "    for i in range(num_tasks):\n",
    "        for j in range(len(preds)):\n",
    "            if targets[j][i] is not None:  # Skip those without targets\n",
    "                valid_preds[i].append(preds[j][i])\n",
    "                valid_targets[i].append(targets[j][i])\n",
    "\n",
    "    result = metric_func(valid_targets[i], valid_preds[i])\n",
    "    print(epoch, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the course of training 30 epochs, the MSE quickly improved and reached to less than 0.1 at the end! Let's take a look at the target vs predicted values. So, we got to this level of prediction without ever specifically wrote code for computing ClogP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = plt.figure(figsize=(4,4))\n",
    "plt.scatter(valid_targets[i], valid_preds[i])\n",
    "plt.xlabel('Target ClogP')\n",
    "plt.ylabel('Predicted ClogP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this post, I have trained a graph neural network that can predict ClogP property. Within 30 epochs, it was able to predict the property pretty accurately in less than 0.1 MSE. Given only very simple features were used in atom and bond features, it was able to \"learn\" to predict the property fairly quickly.\n",
    "\n",
    "Now that we have a trained model, a few things I'd like to try:\n",
    "- compare this model with other traditional model and compare performance\n",
    "- try different parameters, such as `depth`\n",
    "- try alternative featurization, i.e., add if bond is rotatable in the bond_features and so on.\n",
    "- add long-range connection;current network is limited to chemical bonds, but longer range interaction may also be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
